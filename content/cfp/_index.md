---
title: "Call for Papers"
type: "page"
menu: "main"
featured_image: "img/vancouver.jpg"
---

Our areas of interest include:
1. Practical applications of interpretability insights to address key challenges in AI such as hallucinations, biases, and adversarial robustness, as well as applications in high-stakes, less-explored domains like healthcare, finance, and cybersecurity.
2. Comparative analyses of interpretability-based approaches versus alternative techniques like fine-tuning, prompting, and more.
3. New model architectures, training paradigms or design choices informed by interpretability findings.
4. Incorporating interpretability–often focusing on micro-level decision analysis–into more complex scenarios, like reasoning processes or multi-turn interactions.
5. Developing realistic benchmarking and assessment methods to measure the real-world impact of interpretability insights, particularly in production environments and large-scale models.
6. Critical discussions on the feasibility, limitations, and future directions of actionable interpretability research.
